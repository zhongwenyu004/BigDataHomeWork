使用hive创建自己的数据库zhongwenyu  --> create schema zhongwenyu;
使用zhongwenyu数据库  --> use zhongwenyu;
创建t_user表  --> create table if not exists t_user (UserID String,Sex String,Age String,Occupation String,Zipcode String)
                  ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe' WITH SERDEPROPERTIES ("field.delim"="::");
                  
 创建t_movie表  --> create table if not exists t_movie (MovieID String,MovieName String,MovieType String)
                  ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe' WITH SERDEPROPERTIES ("field.delim"="::");
                  
 创建t_movie表 --> create table if not exists t_rating (UserID String,MovieID String,Rate String,Times String) 
                  ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe' WITH SERDEPROPERTIES ("field.delim"="::");
                  
                 /* (.dat 文件中用 "::" 作为分隔符 所以建表时要设置分隔符;hive 默认分隔符为单字符 多字符需要处理  )*/
将.dat数据导入t_user中  -->     hive> load data local inpath '/data/hive/users.dat'
                                   > overwrite into table t_user;  (overwrite是覆盖，into是追加)
验证导入是否成功 查询数据总条数 --> select * from t_user limit 50;
返回结果
1	F	1	10	48067
2	M	56	16	70072
3	M	25	15	55117
4	M	45	7	02460
5	M	25	20	55455
6	F	50	9	55117
7	M	35	1	06810
8	M	25	12	11413
9	M	25	17	61614
10	F	35	1	95370
11	F	25	1	04093
12	M	25	12	32793
13	M	45	1	93304
14	M	35	0	60126
15	M	25	7	22903
16	F	35	0	20670
17	M	50	1	95350
18	F	18	3	95825
19	M	1	10	48073
20	M	25	14	55113
21	M	18	16	99353
22	M	18	15	53706
Time taken: 0.114 seconds, Fetched: 50 row(s)
作业数据准备结束
